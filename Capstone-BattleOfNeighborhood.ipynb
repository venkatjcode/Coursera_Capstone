{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1 align=center><font size = 5>Capstone Project - The Battle of Neighborhoods</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1 align=left><font size = 3>Introduction</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "There\u2019s an influx of tech companies moving to Austin. Lower costs, laid-back lifestyle continue to draw tech companies to Austin, Texas. According to the Austin Chamber of Commerce, 58 major companies relocated to the Austin area in 2019 alone \u2013 not including tech giants such as Apple, Amazon, and Google, who opened new offices in the region. Tech companies aren\u2019t the only ones who are flocking to Austin, either. Nearly 100 other companies in various sectors have announced that they are moving to the area or expanding their local operations in the coming year. Tens of thousands of well-paying new jobs are on their way to Austin, with more being announced every day."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1 align=left><font size = 3>Business Problem</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "All those jobs are going to require smart, motivated, skilled workers to fill them. And those workers need places to live and restaurants or food joints to eat. The objective of this capstone project is to find the most suitable location for an entrepreneur to open a new Italian restaurant in Austin, Texas. By using data science and machine learning methods such as clustering, this project will recommend a best suitable location to open a new Italian restaurant. As with any business, restaurant in particular location is of utmost importance, so we will take serveral things into consideration and suggest an optimal location."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1 align=left><font size = 3>Data</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Following data is required for this project:\n<br>\n<li> List of Austin neighborhoods scraped from Wikipedia page that contains list of Austin neighborhoods </li>\n<br>\n<li> Latitude and Longitude of these neighborhoods, which can be obtained from Geocoder package</li>\n<br>\n<li> Venue data related to these neighborhoods that can be obtained using Foursquare API</li>\n<br>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1 align=left><font size = 3>Methodology</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this project the first step will be to collect data on the neighbourhoods of Austin from <a href=\"https://en.wikipedia.org/wiki/List_of_Austin_neighborhoods\"> Wikipedia </a>. Since the data is not available preformatted, it has to be scraped from Wiki webpage. The location coordinates of each neighbourhood will then be obtained with the help of GeoPy Nominatim geolocator and appended to the neighbourhood data. Using this data, a folium map of Austin neighbourhoods will be created.\n\nThe second step will be to explore each of neighbourhoods and their venues using Foursquare location data. The venues of the neighbourhoods will be analyzed in detail and patterns will be discovered. This discovery of patterns will be carried out by grouping the neighbourhoods using k-means clustering. K-means clustering algorithm identifies k number of centeriods, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible. It is one of the simplest and popular unsupervised machine learning algorithms and it is highly suited for this project as well.Following this, each cluster will be examined and a decision will be made regarding which cluster fits our need. The factor that will determine this is the frequency of occurrence of restaurants and other food venues within the cluster.\n\nOnce a cluster is picked, the neighbourhoods in that cluster will be investigated with regards to the number of Italian restaurants in its vicinity. The results of the analysis will highlight potential neighbourhoods where an Italian restaurant may be opened based on geographical location and proximity to competitors. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\nimport lxml.html as lh\nimport re\n\nimport numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n!conda install -c conda-forge folium=0.5.0 --yes \nimport folium # map rendering library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Load the data hosted on Wikipedia"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "List_url = \"https://en.wikipedia.org/wiki/List_of_Austin_neighborhoods\"\nsource = requests.get(List_url).text\nsoup = BeautifulSoup(source,\"html.parser\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a Dataframe to store the data"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import re\nlis_toc = []\n\n#capture all table of content list, so they can be excluded from the location dataframe\nfor tag in soup.find_all('li', class_=re.compile(\"toc\")):\n    lis_toc.append(tag.text)\ndf_toc = pd.DataFrame(lis_toc)\ndf_toc.columns = ['Neighborhood']\n\n#capture all li content, Woodstone Village is the last neighborhood in Wikipedia\nlis_neighbor = []\nfor tag in soup.find_all('li'):\n    lis_neighbor.append(tag.text)\n    if(tag.text == \"Woodstone Village\"):\n        break\ndf_neighbors = pd.DataFrame(lis_neighbor)\ndf_neighbors.columns = ['Neighborhood']\n\n# remove table of content list from the neighborhood dataframe leaving with the right neighborhoods\ncond = df_neighbors['Neighborhood'].isin(df_toc['Neighborhood'])\ndf_neighbors.drop(df_neighbors[cond].index, inplace = True)\ndf_neighbors.reset_index(inplace=True,drop=True)\n\n#Wiki text for these 4 neighborhoods needs to be cleansed\ndf_neighbors.loc[89,'Neighborhood'] ='Sunset Valley'\ndf_neighbors.loc[83,'Neighborhood'] ='Slaughter-Manchaca'\ndf_neighbors.loc[68,'Neighborhood'] ='South Lamar'\ndf_neighbors.loc[43,'Neighborhood'] ='Great Hills'\n\ndf_neighbors"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# define the data frame columns\ncolumn_names = ['Neighborhood', 'Latitude', 'Longitude'] \n\n# instantiate the data frame\ngeo_neighborhoods = pd.DataFrame(columns=column_names)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "geolocator = Nominatim(user_agent=\"Austin_Explorer\",timeout=5)\nfor i in range(0,len(df_neighbors)):\n    \n    address = df_neighbors.Neighborhood[i]+', Austin'\n    location = geolocator.geocode(address)\n    if location == None:\n        latitude = 0\n        longitude = 0\n    else:\n        latitude = location.latitude\n        longitude = location.longitude\n\n    geo_neighborhoods = geo_neighborhoods.append({'Neighborhood': df_neighbors.Neighborhood[i],\n                                              'Latitude': latitude,\n                                              'Longitude': longitude}, ignore_index=True)\ngeo_neighborhoods"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Data Cleaning\nRemove Neighborhoodd with missing geo coordinates"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "city = \"Austin, TX\"\ngeolocator = Nominatim(user_agent=\"austin_explorer\")\nlocation = geolocator.geocode(city)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Austin city are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "geo_neighborhoods['Latitude']=geo_neighborhoods['Latitude'].astype(float)\ngeo_neighborhoods['Longitude']=geo_neighborhoods['Longitude'].astype(float)\n\ngeo_neighborhoods=geo_neighborhoods[(geo_neighborhoods.Latitude>29.8) & (geo_neighborhoods.Latitude<30.7) & (geo_neighborhoods.Longitude<-97)] \ngeo_neighborhoods.reset_index(inplace=True,drop=True)\ngeo_neighborhoods"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1><font size = 3>Part 2 Coordinates - Latitude and Longitude of each neighborhood</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1><font size = 3>Part 3 Cluster Neighborhoods in Austin</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a map of Toronto with neighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Austin_map = folium.Map(location=[latitude, longitude], zoom_start=10)\nAustin_map"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Add markers for Boroughs"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for lat, lng, neighborhood in zip(\n        geo_neighborhoods['Latitude'], \n        geo_neighborhoods['Longitude'],         \n        geo_neighborhoods['Neighborhood']):\n    label = '{}'.format(neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(Austin_map)  \n\nAustin_map"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Configure Foursquare handle with required Credentials and Version <br>\n*client_id and client_secret removed prior to Github commit"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "CLIENT_ID = 'SRKLHU1PFN2HTF4KMNXVLPSEAJKQXZRCJ32Z1AI3QVKOPWYB'\nCLIENT_SECRET = 'TFQ40LKAZ1X3GUYPUL12TG0U0FDWG4XEWQQEDMMFUD4DD04G'\nVERSION = '20180605'"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes):\n    radius=500\n    LIMIT=100\n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        #print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "austin_venues = getNearbyVenues(names=geo_neighborhoods['Neighborhood'],\n                                   latitudes=geo_neighborhoods['Latitude'],\n                                   longitudes=geo_neighborhoods['Longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "austin_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "venue_count = austin_venues.groupby('Neighborhood').count()\nvenue_count.drop(venue_count.columns[[0,1,3,4,5]], axis=1,inplace=True)\nvenue_count.reset_index(inplace=True)\n\nsuitable_neighborhoods=venue_count[(venue_count.Venue>=10)]\nsuitable_neighborhoods.reset_index(drop=True,inplace=True)\nsuitable_neighborhoods"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's review all venues in the suitable neighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "majorvenues_list=suitable_neighborhoods['Neighborhood'].values.tolist()\n\nfor i in range(0,len(austin_venues)):\n\n    if austin_venues.iloc[i,0] not in majorvenues_list:\n        austin_venues.iloc[i,0]='TO DROP'\n\naustin_venues=austin_venues[austin_venues.Neighborhood!='TO DROP']\naustin_venues.reset_index(drop=True,inplace=True)\naustin_venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\naustin_onehot = pd.get_dummies(austin_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\naustin_onehot.drop(['Neighborhood'],axis=1,inplace=True) \n#austin_onehot['Neighborhood'] = austin_venues['Neighborhood']\naustin_onehot.insert(loc=0, column='Neighborhood', value=austin_venues['Neighborhood'] )\naustin_onehot.shape\naustin_onehot"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "austin_grouped = austin_onehot.groupby('Neighborhood').mean().reset_index()\naustin_grouped.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = austin_grouped['Neighborhood']\n\nfor ind in np.arange(austin_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(austin_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Write about clustering"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The first step is to determine the optimal value of K for the dataset using the Silhouette Coefficient Method.\n\nA higher Silhouette Coefficient score relates to a model with better defined clusters.\n\nA higher Silhouette Coefficient indicates that the object is well matched to its own cluster and poorly matched to neighbouring clusters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import silhouette_score\n\naustin_grouped_clustering = austin_grouped.drop('Neighborhood', 1)\n\nfor n_cluster in range(2, 10):\n    kmeans = KMeans(n_clusters=n_cluster).fit(austin_grouped_clustering)\n    label = kmeans.labels_\n    sil_coeff = silhouette_score(austin_grouped_clustering, label, metric='euclidean')\n    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The Silhouette Coefficient is the highest for n_clusters=3. Therefore, the neighbourhoods shall be grouped into 4 clusters (k=4) using k-means clustering."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 3\n\naustin_grouped_clustering = austin_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(austin_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\naustin_merged = geo_neighborhoods\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\naustin_merged = austin_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n#austin_merged.dropna(inplace=True)\n#austin_merged['Cluster Labels'] = austin_merged['Cluster Labels'].astype(int)\naustin_merged.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\nrainbow[2]='#006000'\nrainbow[1]='#006ff6'\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(austin_merged['Latitude'], austin_merged['Longitude'], austin_merged['Neighborhood'], austin_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    print (label)\n    print(cluster)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Examine the Clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 4, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}